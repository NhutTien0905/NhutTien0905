{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_2_hidden.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IPyG7popyoeGvBn-1sXoFnH0WpNs5YlT",
      "authorship_tag": "ABX9TyP/3hpfEl6/9+myOJ0RdE9d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NhutTien0905/NhutTien0905/blob/main/mnist_2_hidden.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N-8fF7xKiyOh"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(trainX,trainy), (testX,testy) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxugGwLvi9Cg",
        "outputId": "cf8859dc-d4dc-442e-d890-dc40c8912bec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-J4x9_qjFLi",
        "outputId": "30e7c283-c6fc-4a1b-89b9-4aacc69641d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "734FLAcsjI3h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(trainX[0])\n",
        "plt.show()\n",
        "print(trainy[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "dATCvoRPjOuI",
        "outputId": "aba269d2-6489-431e-e533-ba8fa3f9c462"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def NumtoVec(n,maxLength = 10):\n",
        "    vec = np.zeros(maxLength)\n",
        "    vec[n] = 1\n",
        "    vec.reshape(1,maxLength)\n",
        "    return vec"
      ],
      "metadata": {
        "id": "xv29dQ7LjVwe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subTrainX = []\n",
        "subTrainy = []\n",
        "trainPair = list(zip(trainX,trainy))\n",
        "random.shuffle(trainPair)\n",
        "nSample = 2000\n",
        "for i in range(nSample):\n",
        "    x, y = trainPair[i]\n",
        "    x = x.flatten()\n",
        "    x = x.reshape(1,len(x))\n",
        "    subTrainX.append(x)\n",
        "    y = NumtoVec(y)\n",
        "    subTrainy.append(y)"
      ],
      "metadata": {
        "id": "EEdc28NbjwaV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork():\n",
        "    def __init__(self,Xs,Ys,inputS,hiddenS1,hiddenS2,outputS):\n",
        "        self.Xs = Xs\n",
        "        self.Ys = Ys\n",
        "        self.inputS = inputS\n",
        "        self.hiddenS1 = hiddenS1\n",
        "        self.hiddenS2 = hiddenS2\n",
        "        self.outputS = outputS\n",
        "\n",
        "    def generateWeight(self,inputt,outputt):\n",
        "        return np.random.rand(outputt,inputt + 1).transpose() - 0.5\n",
        "\n",
        "    def sigmoid(self,z):\n",
        "        return 1/(1+np.exp(-z))\n",
        "\n",
        "    def addBias(self,x):\n",
        "        curLen = len(x.flatten())\n",
        "        return np.concatenate(([1],x.flatten())).reshape(1,curLen+1)\n",
        "\n",
        "    def forward(self,x,w1,w2,w3):\n",
        "        a1 = x #(1,784)\n",
        "        a1_bias = self.addBias(a1) #(1,785)\n",
        "        z2 = np.matmul(a1_bias,w1) #(1,785)x(785,100)\n",
        "        a2 = self.sigmoid(z2) #(1,100)\n",
        "        a2_bias = self.addBias(a2) #(1,101)\n",
        "        z3 = np.matmul(a2_bias,w2) #(1,101)x(101,100)\n",
        "        a3 = self.sigmoid(z3) # (1,100)\n",
        "        a3_bias = self.addBias(a3) #(1,101)\n",
        "        z4 = np.matmul(a3_bias,w3) #(1,101)x(101,10)\n",
        "        a4 = self.sigmoid(z4) #(1,10)\n",
        "        return a1_bias,a2,a2_bias,a3,a3_bias,a4\n",
        "\n",
        "    def backward(self,x,y,w1,w2,w3):\n",
        "        a1_bias,a2,a2_bias,a3,a3_bias,a4 = self.forward(x,w1,w2,w3)\n",
        "\n",
        "        d4 = a4 - y #(1,10)\n",
        "        # (1,10)x(10,101) * (1,101)\n",
        "        d3 = (np.matmul(d4,w3.transpose())) * (a3_bias*(1-a3_bias))\n",
        "        # (1,100)x(100,101) * (1,101)\n",
        "        d2 = (np.matmul(d3[:,1:],w2.transpose())) * (a2_bias*(1-a2_bias))\n",
        "\n",
        "        delta1 = np.matmul(a1_bias.transpose(), d2) # (785,1)x(1,101)->(785,101)\n",
        "        delta2 = np.matmul(a2_bias.transpose(), d3) # (101,1)x(1,101)->(101,101)\n",
        "        delta3 = np.matmul(a3_bias.transpose(), d4) # (101,1)x(1,10)->(101,10)\n",
        "\n",
        "        return delta1,delta2,delta3\n",
        "\n",
        "    def mse(self,pred,y):\n",
        "        return np.mean(np.power(pred - y,2))\n",
        "\n",
        "    def train(self,epochs,w1,w2,w3,lr):\n",
        "        acc = []\n",
        "        losses = []\n",
        "        for epoch in range(epochs):\n",
        "            capDelta1 = 0\n",
        "            capDelta2 = 0\n",
        "            capDelta3 = 0\n",
        "            correctCase = 0\n",
        "            l = []\n",
        "            for i in range(len(self.Xs)):\n",
        "                x = self.Xs[i]\n",
        "                y = self.Ys[i]\n",
        "                a1_bias,a2,a2_bias,a3,a3_bias,pred = self.forward(x,w1,w2,w3)\n",
        "                if pred.argmax() == y.argmax():\n",
        "                    correctCase += 1\n",
        "                l.append(self.mse(pred,y))\n",
        "                delta1,delta2,delta3 = self.backward(x,y,w1,w2,w3)\n",
        "                capDelta1 += delta1\n",
        "                capDelta2 += delta2\n",
        "                capDelta3 += delta3\n",
        "            # (785,100)     (785,100)\n",
        "            w1 = w1 - lr*capDelta1[:,1:]\n",
        "            # (101,100)     (101,100)\n",
        "            w2 = w2 - lr*capDelta2[:,1:]\n",
        "            # (101,10)      (101,10)\n",
        "            w3 = w3 - lr*capDelta3\n",
        "\n",
        "            curAcc = correctCase*100/len(self.Xs)\n",
        "            acc.append(curAcc)\n",
        "            meanLoss = np.array(l).mean()\n",
        "            losses.append(meanLoss)\n",
        "            freq = 5\n",
        "            if (epoch + 1) % freq == 0:\n",
        "                avgAcc = np.array(acc[-5:]).mean()\n",
        "                loss = np.array(losses[-5:]).mean()\n",
        "                print(f\"Epoch {epoch + 1}: AVG ACC during {freq} epochs: {avgAcc}\")\n",
        "                print(f\"Epoch {epoch + 1}: Loss: {loss}\")\n",
        "        return acc,losses,w1,w2,w3\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "XPj6UJ1rkOyH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputS = 784\n",
        "hiddenS1 = 81\n",
        "hiddenS2 = 81\n",
        "outputS = 10\n"
      ],
      "metadata": {
        "id": "zugTwVHrrGfK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neural = NeuralNetwork(subTrainX,subTrainy,inputS,hiddenS1,hiddenS2,outputS)\n",
        "w1 = neural.generateWeight(inputS,hiddenS1) # (100,785) -> (785,100)\n",
        "w2 = neural.generateWeight(hiddenS1,hiddenS2) # (100,101) -> (101,100)\n",
        "w3 = neural.generateWeight(hiddenS2,outputS) # (10,101) -> (101,10)"
      ],
      "metadata": {
        "id": "iQSQmTUYsR2I"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.00003\n",
        "acc,losses,w1,w2,w3 = neural.train(200,w1,w2,w3,lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vX-KaiXu74v",
        "outputId": "c03b902b-5626-4408-e66b-ba511d4ea408"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: AVG ACC during 5 epochs: 71.24\n",
            "Epoch 5: Loss: 0.052528173277592474\n",
            "Epoch 10: AVG ACC during 5 epochs: 71.25\n",
            "Epoch 10: Loss: 0.05238285724288365\n",
            "Epoch 15: AVG ACC during 5 epochs: 71.25\n",
            "Epoch 15: Loss: 0.05223452295865746\n",
            "Epoch 20: AVG ACC during 5 epochs: 71.27000000000001\n",
            "Epoch 20: Loss: 0.0520850196266278\n",
            "Epoch 25: AVG ACC during 5 epochs: 71.41\n",
            "Epoch 25: Loss: 0.05193699785117758\n",
            "Epoch 30: AVG ACC during 5 epochs: 71.53\n",
            "Epoch 30: Loss: 0.051793093969836015\n",
            "Epoch 35: AVG ACC during 5 epochs: 71.62\n",
            "Epoch 35: Loss: 0.05164991308466055\n",
            "Epoch 40: AVG ACC during 5 epochs: 71.67\n",
            "Epoch 40: Loss: 0.05148175445003238\n",
            "Epoch 45: AVG ACC during 5 epochs: 71.75\n",
            "Epoch 45: Loss: 0.05132418303138392\n",
            "Epoch 50: AVG ACC during 5 epochs: 71.76\n",
            "Epoch 50: Loss: 0.05117627180948292\n",
            "Epoch 55: AVG ACC during 5 epochs: 71.7\n",
            "Epoch 55: Loss: 0.051038639961132684\n",
            "Epoch 60: AVG ACC during 5 epochs: 71.7\n",
            "Epoch 60: Loss: 0.05090220431372755\n",
            "Epoch 65: AVG ACC during 5 epochs: 71.68999999999998\n",
            "Epoch 65: Loss: 0.05076604457119229\n",
            "Epoch 70: AVG ACC during 5 epochs: 71.67\n",
            "Epoch 70: Loss: 0.05062659407571346\n",
            "Epoch 75: AVG ACC during 5 epochs: 71.76\n",
            "Epoch 75: Loss: 0.05049672492226696\n",
            "Epoch 80: AVG ACC during 5 epochs: 71.8\n",
            "Epoch 80: Loss: 0.050365223344533375\n",
            "Epoch 85: AVG ACC during 5 epochs: 71.83\n",
            "Epoch 85: Loss: 0.05023859853261316\n",
            "Epoch 90: AVG ACC during 5 epochs: 72.01\n",
            "Epoch 90: Loss: 0.05009645501370545\n",
            "Epoch 95: AVG ACC during 5 epochs: 72.15\n",
            "Epoch 95: Loss: 0.04996291323759563\n",
            "Epoch 100: AVG ACC during 5 epochs: 72.26\n",
            "Epoch 100: Loss: 0.0498368393281175\n",
            "Epoch 105: AVG ACC during 5 epochs: 72.41\n",
            "Epoch 105: Loss: 0.04970818338426687\n",
            "Epoch 110: AVG ACC during 5 epochs: 72.45\n",
            "Epoch 110: Loss: 0.04957407251769664\n",
            "Epoch 115: AVG ACC during 5 epochs: 72.46000000000001\n",
            "Epoch 115: Loss: 0.049447121340345915\n",
            "Epoch 120: AVG ACC during 5 epochs: 72.53\n",
            "Epoch 120: Loss: 0.04931872716530583\n",
            "Epoch 125: AVG ACC during 5 epochs: 72.55\n",
            "Epoch 125: Loss: 0.04918685009510869\n",
            "Epoch 130: AVG ACC during 5 epochs: 72.54\n",
            "Epoch 130: Loss: 0.04905646587287169\n",
            "Epoch 135: AVG ACC during 5 epochs: 72.58999999999999\n",
            "Epoch 135: Loss: 0.04893603670963688\n",
            "Epoch 140: AVG ACC during 5 epochs: 72.72\n",
            "Epoch 140: Loss: 0.0488163520809182\n",
            "Epoch 145: AVG ACC during 5 epochs: 72.9\n",
            "Epoch 145: Loss: 0.04869857875977224\n",
            "Epoch 150: AVG ACC during 5 epochs: 72.96000000000001\n",
            "Epoch 150: Loss: 0.0485815387924526\n",
            "Epoch 155: AVG ACC during 5 epochs: 73.11999999999999\n",
            "Epoch 155: Loss: 0.04846717643075985\n",
            "Epoch 160: AVG ACC during 5 epochs: 73.2\n",
            "Epoch 160: Loss: 0.048356417248612005\n",
            "Epoch 165: AVG ACC during 5 epochs: 73.29\n",
            "Epoch 165: Loss: 0.04824307955559423\n",
            "Epoch 170: AVG ACC during 5 epochs: 73.30999999999999\n",
            "Epoch 170: Loss: 0.0481444492362175\n",
            "Epoch 175: AVG ACC during 5 epochs: 73.33999999999999\n",
            "Epoch 175: Loss: 0.048033339281355315\n",
            "Epoch 180: AVG ACC during 5 epochs: 73.44\n",
            "Epoch 180: Loss: 0.047896736718320926\n",
            "Epoch 185: AVG ACC during 5 epochs: 73.53\n",
            "Epoch 185: Loss: 0.04778617135680476\n",
            "Epoch 190: AVG ACC during 5 epochs: 73.6\n",
            "Epoch 190: Loss: 0.04767655290335222\n",
            "Epoch 195: AVG ACC during 5 epochs: 73.6\n",
            "Epoch 195: Loss: 0.047572900344252426\n",
            "Epoch 200: AVG ACC during 5 epochs: 73.7\n",
            "Epoch 200: Loss: 0.0474691082331279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"weight_mnist_2_hidden.txt\",\"a+\") as f:\n",
        "    f.write(str(w1))\n",
        "    f.write(str(w2))\n",
        "    f.write(str(w3))"
      ],
      "metadata": {
        "id": "IsOPC9BnsD7W"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "5z3jZXHpslBC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = [w1,w2,w3]\n",
        "pickle.dump(weights,open(\"train_weights_800_epochs.pickle\",\"wb\"))"
      ],
      "metadata": {
        "id": "wuIUl0j6thrr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1n,w2n,w3n = pickle.load(open(\"/content/train_weights_800_epochs.pickle\",\"rb\"))"
      ],
      "metadata": {
        "id": "f8LOZiUkt_Sd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc,losses,w1n,w2n,w3n = neural.train(50,w1n,w2n,w3n,lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csLtIQDducyw",
        "outputId": "986e64a5-9c3b-4b2e-98d4-99dcfc83fbeb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: AVG ACC during 5 epochs: 73.8\n",
            "Epoch 5: Loss: 0.047367534084688884\n",
            "Epoch 10: AVG ACC during 5 epochs: 73.9\n",
            "Epoch 10: Loss: 0.04725185668297057\n",
            "Epoch 15: AVG ACC during 5 epochs: 73.92\n",
            "Epoch 15: Loss: 0.04712685263683589\n",
            "Epoch 20: AVG ACC during 5 epochs: 73.97\n",
            "Epoch 20: Loss: 0.04701772763308857\n",
            "Epoch 25: AVG ACC during 5 epochs: 73.95\n",
            "Epoch 25: Loss: 0.046912695492077314\n",
            "Epoch 30: AVG ACC during 5 epochs: 73.92\n",
            "Epoch 30: Loss: 0.04681266266635775\n",
            "Epoch 35: AVG ACC during 5 epochs: 73.9\n",
            "Epoch 35: Loss: 0.046711976400008084\n",
            "Epoch 40: AVG ACC during 5 epochs: 74.0\n",
            "Epoch 40: Loss: 0.046609436454703536\n",
            "Epoch 45: AVG ACC during 5 epochs: 74.05\n",
            "Epoch 45: Loss: 0.046509907097086585\n",
            "Epoch 50: AVG ACC during 5 epochs: 74.10999999999999\n",
            "Epoch 50: Loss: 0.046414573955147066\n"
          ]
        }
      ]
    }
  ]
}